{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation Model with Deep Learning and Artificial Intelligence\n",
    "\n",
    "Machine Translation is one of the most challenging tasks in Artificial Intelligence that works by investigating the use of software to translate a text or speech from one language to another. In this project, we will go through Machine Translation using Neural networks.\n",
    "\n",
    "At the end of this project, we will learn to develop a machine translation model using Neural networks. We will use the **English language** as an input and we will train our Machine Translation model to give the output in the **French language**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import helper  # its a .py file\n",
    "import numpy as np\n",
    "# import project_tests as tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper.py file got this funtion\n",
    "# import os\n",
    "\n",
    "# def load_data(path):\n",
    "#     \"\"\"\n",
    "#     Load dataset\n",
    "#     \"\"\"\n",
    "#     input_file = os.path.join(path)\n",
    "#     with open(input_file, \"r\") as f:\n",
    "#         data = f.read()\n",
    "\n",
    "#     return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _test_model(model, input_shape, output_sequence_length, french_vocab_size):\n",
    "#     if isinstance(model, Sequential):\n",
    "#         model = model.model\n",
    "\n",
    "#     assert model.input_shape == (None, *input_shape[1:]),\\\n",
    "#         'Wrong input shape. Found input shape {} using parameter input_shape={}'.format(model.input_shape, input_shape)\n",
    "\n",
    "#     assert model.output_shape == (None, output_sequence_length, french_vocab_size),\\\n",
    "#         'Wrong output shape. Found output shape {} using parameters output_sequence_length={} and french_vocab_size={}'\\\n",
    "#             .format(model.output_shape, output_sequence_length, french_vocab_size)\n",
    "\n",
    "#     assert len(model.loss_functions) &amp;gt; 0,\\\n",
    "#         'No loss function set.  Apply the `compile` function to the model.'\n",
    "\n",
    "#     assert sparse_categorical_crossentropy in model.loss_functions,\\\n",
    "#         'Not using `sparse_categorical_crossentropy` function for loss.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "english_sentences = helper.load_data('small_vocab_en.csv')\n",
    "french_sentences = helper.load_data('small_vocab_fr.csv')\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "small_vocab_fr Line 2:  les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(2):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are doing the translation of a language so the complexity of this problem will be determined by the complexity of the vocabulary. The more complex is the vocabulary of our language is the more complex our problem will be. Let’s look at the data to see what complex data we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n"
     ]
    }
   ],
   "source": [
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "In Machine Learning wherever we are dealing with any sort of text values we first need to convert the text values into sequences of integers by using two primary methods like **Tokenize** and **Padding**. Now let’s start with **Tokenization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False) # By default char_level = False\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n"
     ]
    }
   ],
   "source": [
    "print(text_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use the padding method to make all the sequences of the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing a Pipeline for Machine Translation\n",
    "\n",
    "Now let’s define a preprocessing function to create a Pipeline for the task of Machine Translation so that we could use this model in future also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "    \n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    \n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "preprocess(english_sentences, french_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 199\n",
      "French vocabulary size: 345\n"
     ]
    }
   ],
   "source": [
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network for Machine Translation\n",
    "\n",
    "Now, here we will train a model using Neural networks. Let’s start by creating a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '&amp;lt;PAD&amp;gt;'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: RNN \n",
    "\n",
    "A basic **RNN model** is a good baseline for sequence data. In this model, we will build an **RNN** that translates English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    input_seq = Input(input_shape[1:])\n",
    "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    model.compile(loss = sparse_categorical_crossentropy, optimizer = Adam(learning_rate), metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate of above model\n",
    "\n",
    "# def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "#     \"\"\"\n",
    "#     Build and train a basic RNN on x and y\n",
    "#     :param input_shape: Tuple of input shape\n",
    "#     :param output_sequence_length: Length of output sequence\n",
    "#     :param english_vocab_size: Number of unique English words in the dataset\n",
    "#     :param french_vocab_size: Number of unique French words in the dataset\n",
    "#     :return: Keras model built, but not trained\n",
    "#     \"\"\"\n",
    "#     # TODO: Build the layers\n",
    "#     learning_rate = 1e-3\n",
    "#     model = Sequential()\n",
    "#     model.add(GRU(128, input_shape=input_shape[1:], return_sequences=True))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(GRU(128, return_sequences=True))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "     \n",
    "     \n",
    "#     model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "108/108 [==============================] - 51s 433ms/step - loss: 4.4833 - accuracy: 0.3744 - val_loss: 2.5448 - val_accuracy: 0.4596\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 46s 422ms/step - loss: 2.4929 - accuracy: 0.4701 - val_loss: 2.3267 - val_accuracy: 0.4808\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 46s 427ms/step - loss: 2.2650 - accuracy: 0.4902 - val_loss: 2.0519 - val_accuracy: 0.5393\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 46s 430ms/step - loss: 1.9871 - accuracy: 0.5487 - val_loss: 1.8371 - val_accuracy: 0.5685\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 62s 580ms/step - loss: 1.8003 - accuracy: 0.5715 - val_loss: 1.7111 - val_accuracy: 0.5860\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 57s 523ms/step - loss: 1.6881 - accuracy: 0.5904 - val_loss: 1.6273 - val_accuracy: 0.5945\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 50s 464ms/step - loss: 1.6090 - accuracy: 0.5929 - val_loss: 1.5594 - val_accuracy: 0.6005\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 48s 444ms/step - loss: 1.5453 - accuracy: 0.6017 - val_loss: 1.5003 - val_accuracy: 0.6082\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 48s 445ms/step - loss: 1.4875 - accuracy: 0.6090 - val_loss: 1.4472 - val_accuracy: 0.6196\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 62s 576ms/step - loss: 1.4351 - accuracy: 0.6187 - val_loss: 1.4011 - val_accuracy: 0.6224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd585ede88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(tmp_x.shape,max_french_sequence_length,\n",
    "                                english_vocab_size,french_vocab_size+1) # we added 1 with french_vocab_size+1 otherwise we will get an error of InvalidArgumentError: Received a label value of 345 which is outside the valid range of [0, 345).\n",
    "\n",
    "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=300, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 21, 1)]           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 21, 64)            12864     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 346)           22490     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 21, 346)           0         \n",
      "=================================================================\n",
      "Total params: 35,354\n",
      "Trainable params: 35,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models\\\\rnn_model.h5'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "import os\n",
    "import glob\n",
    " \n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "cache_dir = os.path.join(\"models\")\n",
    "model_file = \"rnn_model.h5\"\n",
    "simple_rnn_model.save(os.path.join(cache_dir, model_file))\n",
    " \n",
    "os.path.join(cache_dir, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey est parfois parfois en l' et il est est en en &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt;\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **RNN model** gave us an accuracy of only **60 per cent**, let’s use a more complex neural network to train our model with better accuracy. We will now train our model using **RNN with embedding**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Embedding\n",
    "\n",
    "We have turned the words into ids, but there’s a better representation of a word. This is called **word embeddings**. \n",
    "\n",
    "* **Embedding** represents a vector of a word that is very close to a similar word in the **n-dimensional** world. \n",
    "* The `n` here represents the size of the vectors of embedding\n",
    "* In this model, we will create an RNN model using embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    learning_rate = 1e-3\n",
    "    rnn = GRU(64, return_sequences=True, activation=\"tanh\")\n",
    "    \n",
    "    embedding = Embedding(french_vocab_size, 64, input_length=input_shape[1]) \n",
    "    logits = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"))\n",
    "    \n",
    "    model = Sequential()\n",
    "    #em can only be used in first layer --&amp;gt; Keras Documentation\n",
    "    model.add(embedding)\n",
    "    model.add(rnn)\n",
    "    model.add(logits)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "                  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate of above model\n",
    "\n",
    "# def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "#     \"\"\"\n",
    "#     Build and train a RNN model using word embedding on x and y\n",
    "#     :param input_shape: Tuple of input shape\n",
    "#     :param output_sequence_length: Length of output sequence\n",
    "#     :param english_vocab_size: Number of unique English words in the dataset\n",
    "#     :param french_vocab_size: Number of unique French words in the dataset\n",
    "#     :return: Keras model built, but not trained\n",
    "#     \"\"\"\n",
    "#     # Implement\n",
    "#     learning_rate= 0.001\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(english_vocab_size, 100, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "     \n",
    "#     model.add(GRU(128, return_sequences=True))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(GRU(128,  return_sequences=True))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "     \n",
    "#     model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "     \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "embeded_model = embed_model(tmp_x.shape,max_french_sequence_length,english_vocab_size,french_vocab_size+1)\n",
    "\n",
    "# or \n",
    "# embeded_model = embed_model(tmp_x.shape,preproc_french_sentences.shape[1],len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "108/108 [==============================] - 72s 622ms/step - loss: 4.6489 - accuracy: 0.3623 - val_loss: 2.9455 - val_accuracy: 0.4097\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 80s 747ms/step - loss: 2.7552 - accuracy: 0.4421 - val_loss: 2.2866 - val_accuracy: 0.5137\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 85s 787ms/step - loss: 2.0772 - accuracy: 0.5511 - val_loss: 1.5426 - val_accuracy: 0.6261\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 76s 701ms/step - loss: 1.4372 - accuracy: 0.6485 - val_loss: 1.1854 - val_accuracy: 0.7113\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 74s 683ms/step - loss: 1.1293 - accuracy: 0.7219 - val_loss: 0.9760 - val_accuracy: 0.7537\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 72s 667ms/step - loss: 0.9384 - accuracy: 0.7633 - val_loss: 0.8354 - val_accuracy: 0.7807\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 77s 715ms/step - loss: 0.8101 - accuracy: 0.7856 - val_loss: 0.7347 - val_accuracy: 0.8014\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 74s 685ms/step - loss: 0.7193 - accuracy: 0.8041 - val_loss: 0.6607 - val_accuracy: 0.8160\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 88s 814ms/step - loss: 0.6454 - accuracy: 0.8193 - val_loss: 0.6039 - val_accuracy: 0.8284\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 81s 753ms/step - loss: 0.5911 - accuracy: 0.8313 - val_loss: 0.5572 - val_accuracy: 0.8402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd58fa6608>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# or\n",
    "# embeded_model.fit(tmp_x, preproc_french_sentences, batch_size=300, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 64)            22144     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 21, 64)            24960     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 21, 346)           22490     \n",
      "=================================================================\n",
      "Total params: 69,594\n",
      "Trainable params: 69,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeded_model.summary()\n",
    "model_file = \"embed_model.h5\"\n",
    "embeded_model.save(os.path.join(cache_dir, model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n"
     ]
    }
   ],
   "source": [
    "print(english_sentences[:1])\n",
    "print(french_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey est parfois calme en l' et et il est neigeux en avril &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt; &amp;lt;PAD&amp;gt;\n"
     ]
    }
   ],
   "source": [
    "print(logits_to_text(embeded_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our **RNN model with embedding** resulted in a very good accuracy of **83 percent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional RNNs\n",
    "\n",
    "One restriction of a RNN is that it can’t see the future input, only the past. This is where bidirectional recurrent neural networks come in. They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,Dropout\n",
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "     \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape[1:]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "     \n",
    "     \n",
    "    model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Print prediction(s)\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Print prediction(s)\n",
    "bd_rnn_model = bd_model(tmp_x.shape,preproc_french_sentences.shape[1],\n",
    "                        len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 413s 1s/step - loss: 2.5090 - accuracy: 0.4990 - val_loss: 1.2650 - val_accuracy: 0.6347\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 463s 1s/step - loss: 1.3316 - accuracy: 0.6209 - val_loss: 1.0823 - val_accuracy: 0.6661\n",
      "Epoch 3/10\n",
      "368/368 [==============================] - 464s 1s/step - loss: 1.1774 - accuracy: 0.6460 - val_loss: 0.9856 - val_accuracy: 0.6803\n",
      "Epoch 4/10\n",
      "368/368 [==============================] - 436s 1s/step - loss: 1.0853 - accuracy: 0.6631 - val_loss: 0.8980 - val_accuracy: 0.7065\n",
      "Epoch 5/10\n",
      "368/368 [==============================] - 466s 1s/step - loss: 1.0103 - accuracy: 0.6820 - val_loss: 0.8420 - val_accuracy: 0.7221\n",
      "Epoch 6/10\n",
      "368/368 [==============================] - 470s 1s/step - loss: 0.9575 - accuracy: 0.6960 - val_loss: 0.8011 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "368/368 [==============================] - 438s 1s/step - loss: 0.9228 - accuracy: 0.7041 - val_loss: 0.7670 - val_accuracy: 0.7432\n",
      "Epoch 8/10\n",
      "368/368 [==============================] - 447s 1s/step - loss: 0.8849 - accuracy: 0.7128 - val_loss: 0.7216 - val_accuracy: 0.7537\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 464s 1s/step - loss: 0.8495 - accuracy: 0.7219 - val_loss: 0.6842 - val_accuracy: 0.7638\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 465s 1s/step - loss: 0.8168 - accuracy: 0.7311 - val_loss: 0.6334 - val_accuracy: 0.7816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd59c30988>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=300, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 21, 256)           100608    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 21, 256)           296448    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 21, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 21, 346)           88922     \n",
      "=================================================================\n",
      "Total params: 551,770\n",
      "Trainable params: 551,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bd_rnn_model.summary()\n",
    "model_file = \"bd_rnn_model.h5\"\n",
    "bd_rnn_model.save(os.path.join(cache_dir, model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_rnn_model.save(\"bd_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Encoder-Decoder \n",
    "\n",
    "Time to look at **encoder-decoder models**. This model is made up of an **encoder** and **decoder**. \n",
    "* The **encoder** creates a matrix representation of the sentence. \n",
    "* The **decoder** takes this matrix as input and predicts the translation as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "     \n",
    "    #Encoder\n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    gru = GRU(output_sequence_length)(inputs)\n",
    "    e_out = Dense(128, activation='relu')(gru)\n",
    "     \n",
    "    #Decoder\n",
    "    d_input = RepeatVector(output_sequence_length)(e_out)\n",
    "    d_gru = GRU(128, return_sequences=True)(d_input)\n",
    "    layer = TimeDistributed(Dense(french_vocab_size, activation='softmax'))\n",
    "    final = layer(d_gru)\n",
    " \n",
    "    #Create Model from parameters defined above\n",
    "    model = Model(inputs=inputs, outputs=final)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Print prediction(s)\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Print prediction(s)\n",
    "\n",
    "ed_rnn_model = encdec_model(tmp_x.shape,preproc_french_sentences.shape[1],\n",
    "                            len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 162s 393ms/step - loss: 3.3029 - accuracy: 0.4299 - val_loss: 2.1442 - val_accuracy: 0.5193\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 117s 319ms/step - loss: 2.0411 - accuracy: 0.5308 - val_loss: 1.8424 - val_accuracy: 0.5488\n",
      "Epoch 3/10\n",
      "368/368 [==============================] - 154s 419ms/step - loss: 1.8046 - accuracy: 0.5511 - val_loss: 1.7304 - val_accuracy: 0.5594\n",
      "Epoch 4/10\n",
      "368/368 [==============================] - 150s 407ms/step - loss: 1.7196 - accuracy: 0.5582 - val_loss: 1.6600 - val_accuracy: 0.5726\n",
      "Epoch 5/10\n",
      "368/368 [==============================] - 173s 470ms/step - loss: 1.6236 - accuracy: 0.5744 - val_loss: 1.4961 - val_accuracy: 0.5947\n",
      "Epoch 6/10\n",
      "368/368 [==============================] - 175s 475ms/step - loss: 1.4821 - accuracy: 0.5963 - val_loss: 1.4290 - val_accuracy: 0.6057\n",
      "Epoch 7/10\n",
      "368/368 [==============================] - 169s 460ms/step - loss: 1.4148 - accuracy: 0.6075 - val_loss: 1.3735 - val_accuracy: 0.6192\n",
      "Epoch 8/10\n",
      "368/368 [==============================] - 181s 493ms/step - loss: 1.3710 - accuracy: 0.6197 - val_loss: 1.3364 - val_accuracy: 0.6280\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 185s 503ms/step - loss: 1.3397 - accuracy: 0.6261 - val_loss: 1.3228 - val_accuracy: 0.6272\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 179s 486ms/step - loss: 1.3142 - accuracy: 0.6296 - val_loss: 1.2960 - val_accuracy: 0.6322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23dcb4d5e08>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=300, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Embeddings and Bidirectional RNN\n",
    "\n",
    "We will create a model that incorporates **embedding** and a **bidirectional RNN** into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # Implement\n",
    "    learning_rate = 0.001\n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    emb = Embedding(english_vocab_size, 100)(inputs)\n",
    "    gru = Bidirectional(GRU(128, dropout=0.5))(emb)\n",
    "    final_enc = Dense(256, activation='relu')(gru)\n",
    "     \n",
    "    dec1 = RepeatVector(output_sequence_length)(final_enc)\n",
    "    decgru = Bidirectional(LSTM(512, dropout=0.2, return_sequences=True))(dec1)\n",
    "    layer = TimeDistributed(Dense(french_vocab_size, activation='softmax'))\n",
    "    final = layer(decgru)\n",
    "     \n",
    "     \n",
    "    model = Model(inputs=inputs, outputs=final)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    # TODO: Train neural network using model_final\n",
    "    model = model_final(\n",
    "        x.shape,\n",
    "        y.shape[1],\n",
    "        len(x_tk.word_index)+1,\n",
    "        len(y_tk.word_index)+1)\n",
    "    print (model.summary())\n",
    "    model.fit(x, y, batch_size=300, epochs=30, validation_split=0.2)\n",
    " \n",
    "     \n",
    "     \n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    " \n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    " \n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 15, 100)           20000     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               176640    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 21, 1024)          3149824   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 346)           354650    \n",
      "=================================================================\n",
      "Total params: 3,766,906\n",
      "Trainable params: 3,766,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "368/368 [==============================] - 2176s 6s/step - loss: 2.3902 - accuracy: 0.5040 - val_loss: 1.0521 - val_accuracy: 0.7025\n",
      "Epoch 2/30\n",
      "140/368 [==========>...................] - ETA: 24:49 - loss: 1.0457 - accuracy: 0.6972"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-88aa0e2651c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreproc_english_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc_french_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menglish_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-e697186d0c36>\u001b[0m in \u001b[0;36mfinal_predictions\u001b[1;34m(x, y, x_tk, y_tk)\u001b[0m\n\u001b[0;32m     14\u001b[0m         len(y_tk.word_index)+1)\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
